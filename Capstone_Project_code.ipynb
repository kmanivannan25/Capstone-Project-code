{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Lib and data\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "import math\n",
    "from scipy import stats\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Mani\\\\Data_Science\\\\Final_project_Capstone\")\n",
    "Data=pd.read_csv(\"Data_Modeling_Resp1_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.decribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA \n",
    "Data['Response1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Occupancy_Status',data=Data, palette='hls')\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='season1',data=Data, palette='hls')\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(Data.season1,Data.Response1).plot(kind='bar')\n",
    "plt.title('Assets sold frequency')\n",
    "plt.xlabel('season1')\n",
    "plt.ylabel('Assets sold')\n",
    "plt.savefig('Assets sold within and after 90 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(Data.Rural_Urban,Data.Response1).plot(kind='bar')\n",
    "plt.title('Assets sold frequency')\n",
    "plt.xlabel('Rural_Urban')\n",
    "plt.ylabel('Assets sold')\n",
    "plt.savefig('Assets sold within and after 90 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(Data.Bath_Count,Data.Response1).plot(kind='bar')\n",
    "plt.title('Assets sold frequency')\n",
    "plt.xlabel('Bath_Count')\n",
    "plt.ylabel('Assets sold')\n",
    "plt.savefig('Assets sold within and after 90 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(Data.Bed_Count,Data.Response1).plot(kind='bar')\n",
    "plt.title('Assets sold frequency')\n",
    "plt.xlabel('Bed_Count')\n",
    "plt.ylabel('Assets sold')\n",
    "plt.savefig('Assets sold within and after 90 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(Data.Occupancy_Statuswoe,Data.Response1).plot(kind='bar')\n",
    "plt.title('Assets sold frequency')\n",
    "plt.xlabel('Occupancy_Statuswoe')\n",
    "plt.ylabel('Assets sold')\n",
    "plt.savefig('Assets sold within and after 90 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(Data.season1woe,Data.Response1).plot(kind='bar')\n",
    "plt.title('Assets sold frequency')\n",
    "plt.xlabel('season1woe')\n",
    "plt.ylabel('Assets sold')\n",
    "plt.savefig('Assets sold within and after 90 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating WOE and IV\n",
    "class WOE:\n",
    "    def __init__(self):\n",
    "        self._WOE_MIN = -20\n",
    "        self._WOE_MAX = 20\n",
    "\n",
    "    def woe(self, X, y, event=1):\n",
    "       \n",
    "        self.check_target_binary(y)\n",
    "        X1 = self.feature_discretion(X)\n",
    "\n",
    "        res_woe = []\n",
    "        res_iv = []\n",
    "        for i in range(0, X1.shape[-1]):\n",
    "            x = X1[:, i]\n",
    "            woe_dict, iv1 = self.woe_single_x(x, y, event)\n",
    "            res_woe.append(woe_dict)\n",
    "            res_iv.append(iv1)\n",
    "        return np.array(res_woe), np.array(res_iv)\n",
    "\n",
    "    def woe_single_x(self, x, y, event=1):\n",
    "       \n",
    "        self.check_target_binary(y)\n",
    "\n",
    "        event_total, non_event_total = self.count_binary(y, event=event)\n",
    "        x_labels = np.unique(x)\n",
    "        woe_dict = {}\n",
    "        iv = 0\n",
    "        for x1 in x_labels:\n",
    "            y1 = y[np.where(x == x1)[0]]\n",
    "            event_count, non_event_count = self.count_binary(y1, event=event)\n",
    "            rate_event = 1.0 * event_count / event_total\n",
    "            rate_non_event = 1.0 * non_event_count / non_event_total\n",
    "            if rate_event == 0:\n",
    "                woe1 = self._WOE_MIN\n",
    "            elif rate_non_event == 0:\n",
    "                woe1 = self._WOE_MAX\n",
    "            else:\n",
    "                woe1 = math.log(rate_event / rate_non_event)\n",
    "            woe_dict[x1] = woe1\n",
    "            iv += (rate_event - rate_non_event) * woe1\n",
    "        return woe_dict, iv\n",
    "\n",
    "    def woe_replace(self, X, woe_arr):\n",
    "        \n",
    "      \n",
    "        if X.shape[-1] != woe_arr.shape[-1]:\n",
    "            raise ValueError('WOE dict array')\n",
    "\n",
    "        res = np.copy(X).astype(float)\n",
    "        idx = 0\n",
    "        for woe_dict in woe_arr:\n",
    "            for k in woe_dict.keys():\n",
    "                woe = woe_dict[k]\n",
    "                res[:, idx][np.where(res[:, idx] == k)[0]] = woe * 1.0\n",
    "            idx += 1\n",
    "\n",
    "        return res\n",
    "\n",
    "    def combined_iv(self, X, y, masks, event=1):\n",
    "        \n",
    "        if masks.shape[-1] != X.shape[-1]:\n",
    "            raise ValueError('Masks array length')\n",
    "\n",
    "        x = X[:, np.where(masks == 1)[0]]\n",
    "        tmp = []\n",
    "        for i in range(x.shape[0]):\n",
    "            tmp.append(self.combine(x[i, :]))\n",
    "\n",
    "        dumy = np.array(tmp)\n",
    "        # dumy_labels = np.unique(dumy)\n",
    "        woe, iv = self.woe_single_x(dumy, y, event)\n",
    "        return woe, iv\n",
    "\n",
    "    def combine(self, list):\n",
    "        res = ''\n",
    "        for item in list:\n",
    "            res += str(item)\n",
    "        return res\n",
    "\n",
    "    def count_binary(self, a, event=1):\n",
    "        event_count = (a == event).sum()\n",
    "        non_event_count = a.shape[-1] - event_count\n",
    "        return event_count, non_event_count\n",
    "\n",
    "    def check_target_binary(self, y):\n",
    "        \n",
    "        y_type = type_of_target(y)\n",
    "        if y_type not in ['binary']:\n",
    "            raise ValueError('Label type must be binary')\n",
    "\n",
    "    def feature_discretion(self, X):\n",
    "        \n",
    "        temp = []\n",
    "        for i in range(0, X.shape[-1]):\n",
    "            x = X[:, i]\n",
    "            x_type = type_of_target(x)\n",
    "            if x_type == 'continuous':\n",
    "                x1 = self.discrete(x)\n",
    "                temp.append(x1)\n",
    "            else:\n",
    "                temp.append(x)\n",
    "        return np.array(temp).T\n",
    "\n",
    "    def discrete(self, x):\n",
    "        \n",
    "        res = np.array([0] * x.shape[-1], dtype=int)\n",
    "        for i in range(5):\n",
    "            point1 = stats.scoreatpercentile(x, i * 20)\n",
    "            point2 = stats.scoreatpercentile(x, (i + 1) * 20)\n",
    "            x1 = x[np.where((x >= point1) & (x <= point2))]\n",
    "            mask = np.in1d(x, x1)\n",
    "            res[mask] = (i + 1)\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def WOE_MIN(self):\n",
    "        return self._WOE_MIN\n",
    "    @WOE_MIN.setter\n",
    "    def WOE_MIN(self, woe_min):\n",
    "        self._WOE_MIN = woe_min\n",
    "    @property\n",
    "    def WOE_MAX(self):\n",
    "        return self._WOE_MAX\n",
    "    @WOE_MAX.setter\n",
    "    def WOE_MAX(self, woe_max):\n",
    "        self._WOE_MAX = woe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Tain data spilt\n",
    "train, test = train_test_split(Data, train_size=0.80, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualityTrain = pd.DataFrame(train, columns=Data.columns)\n",
    "qualityTest = pd.DataFrame(test, columns=Data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Agent_Prop_Conditionwoe','state1woe','PROPERTY_TYPEwoe','Census_Urban_Ruralwoe',\n",
    " 'Occupancy_Statuswoe',\n",
    " 'season1woe',\n",
    " 'Rural_Urbanwoe',\n",
    " 'bath_binwoe',\n",
    " 'bed_binwoe',\n",
    " 'age_yr_bin1woe',\n",
    " 'upb_fc_bin1woe',\n",
    " 'sqft_drift_binwoe',\n",
    " 'price_drift_binwoe',\n",
    "'state_drift_bin1woe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = qualityTest[cols]\n",
    "x = sm.add_constant(x)\n",
    "y = qualityTest['Response1']\n",
    "z = qualityTest['Response1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = sm.Logit(y, x.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x)\n",
    "pred=np.where(pred > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(z, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision(sensitivity), Recall(specificity)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(z, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(z, pred)\n",
    "roc_auc=metrics.auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Sold and Unsold assest characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 2], [0, 2],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('Logistic_ROC_curve.pdf') \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(z, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GINI = (2 * roc_auc) - 1\n",
    "print(GINI)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
